{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "invisible",
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "with open('../model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "train = pd.read_pickle('train.pkl')\n",
    "valid = pd.read_pickle('valid.pkl')\n",
    "target_col = 'loan_status'\n",
    "train_data = train.drop(target_col, 1)\n",
    "valid_data = valid.drop(target_col, 1)\n",
    "train_scores = model.predict_proba(X = train_data)\n",
    "train_predictions = model.predict(X = train_data)\n",
    "valid_scores = model.predict_proba(X = valid_data)\n",
    "valid_predictions = model.predict(X = valid_data)\n",
    "positive_class = True\n",
    "index_positive = np.min(np.where(model.named_steps['classifier'].classes_ == positive_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier with Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "model.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "top_n_features = 10\n",
    "importances = model.named_steps['classifier'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(0,top_n_features):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(range(0,top_n_features), importances[indices][0:top_n_features],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(0,top_n_features), indices)\n",
    "plt.xlim([-1, top_n_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true=train[target_col],\n",
    "                      y_pred=train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true=valid[target_col],\n",
    "                      y_pred=valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=valid[target_col],\n",
    "                 y_pred=valid_predictions)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "#ax.set_xticklabels([''] + labels)\n",
    "#ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_true= valid[target_col],\n",
    "              y_score = valid_scores[:,index_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true= valid[target_col], y_score=valid_scores[:,index_positive])\n",
    "plt.plot(fpr, tpr, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "valid_data_predictions = valid_data.assign(scores = pd.Series(valid_scores[:,index_positive]).values)\n",
    "high_predictions = valid_data_predictions[valid_data_predictions.scores > 0.98]\n",
    "low_predictions = valid_data_predictions[valid_data_predictions.scores < 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "high_predictions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [],
   "source": [
    "low_predictions.head(20)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
